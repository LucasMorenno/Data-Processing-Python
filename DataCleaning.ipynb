{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Data cleaning and preparation for financial analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### This notebook was created to show how I prepared a dataset to analyze my financial spending data, using credit card, for the years 2018, 2019 and 2020. To analyze the 3 years of my personal sppending, I had to unify the 3 differente files in one. The first problem: I updated almost twice a year the excel file to optimize record information and analysis. So, I had to read each year file and see the differences in each month, correct the differences and create a standard table. Then I created a unique file to join the 3 years.\n",
    "\n",
    "\n",
    "##### **The operations applied on the process are as shown below:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Creating a Data Frame\n",
    "2. Performing operations on Rows and Columns\n",
    "3. Data Selection, addition, deletion\n",
    "4. Exporting a CSV file\n",
    "5. Exporting Excel file\n",
    "6. Unifying the 3 excel files (2018, 2019 e 2020)\n",
    "7. Using Excel to correct data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.Creating a Data Frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The first pandas operation was read an excel file of 2018. This operation returns a dict which each item corresponds to a sheet, this one is the data frame of each month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas library\n",
    "import pandas as pd\n",
    "\n",
    "# Creating a dict of data frames\n",
    "dictdf = pd.read_excel('1.2018.Tables.xlsx', None)\n",
    "# dictdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.Performing operations on Rows and Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The name of sheets in the file is the full name of the respective month (in portuguese), so I created a list with month names for further operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Janeiro, Fevereiro, Março, Abril, Maio, Junho, Julho, Agosto, Setembro, Outubro, Novembro, Dezembro, "
     ]
    }
   ],
   "source": [
    "# Creating the list of the names\n",
    "months = []\n",
    "\n",
    "# Inserting the sheet names (months) in the list by using a loop.\n",
    "for m in dictdf.keys():\n",
    "    months.append(m)\n",
    "    print(m, end=\", \")\n",
    "\n",
    "# months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 10)\n",
      "(56, 10)\n",
      "(35, 10)\n",
      "(40, 10)\n",
      "(41, 10)\n",
      "(55, 10)\n",
      "(53, 10)\n",
      "(64, 10)\n",
      "(54, 10)\n",
      "(68, 10)\n",
      "(131, 9)\n",
      "(92, 9)\n"
     ]
    }
   ],
   "source": [
    "# Using shape method to see the differences between sheets.\n",
    "for m in months:\n",
    "    print(dictdf[m].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### *Note that the 2 last months shows a higher number of rows and 1 less column.*\n",
    "\n",
    "##### This is because in the first file model I was recording the spending by credit in a table separated from spending by debit/cash. After I update the file, I started recording both (credit and debit) in a single table, which I need to arrange to be able to joint the sheets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Local', 'Pessoa', 'Data', 'Mês', 'Ano', 'Ítem', 'Motivo', 'Tipo',\n",
      "       'Cartão', 'Valor'],\n",
      "      dtype='object')\n",
      "Index(['Local', 'Pessoa', 'Data', 'Mês', 'Ano', 'Ítem', 'Motivo', 'Tipo',\n",
      "       'Cartão', 'Valor'],\n",
      "      dtype='object')\n",
      "Index(['Local', 'Pessoa', 'Data', 'Mês', 'Ano', 'Ítem', 'Motivo', 'Tipo',\n",
      "       'Cartão', 'Valor'],\n",
      "      dtype='object')\n",
      "Index(['Local', 'Pessoa', 'Data', 'Mês', 'Ano', 'Ítem', 'Motivo', 'Tipo',\n",
      "       'Cartão', 'Valor'],\n",
      "      dtype='object')\n",
      "Index(['Local', 'Pessoa', 'Data', 'Mês', 'Ano', 'Ítem', 'Motivo', 'Tipo',\n",
      "       'Cartão', 'Valor'],\n",
      "      dtype='object')\n",
      "Index(['Local', 'Pessoa', 'Data', 'Mês', 'Ano', 'Ítem', 'Motivo', 'Tipo',\n",
      "       'Cartão', 'Valor'],\n",
      "      dtype='object')\n",
      "Index(['Local', 'Pessoa', 'Data', 'Mês', 'Ano', 'Ítem', 'Motivo', 'Tipo',\n",
      "       'Cartão', 'Valor'],\n",
      "      dtype='object')\n",
      "Index(['Local', 'Pessoa', 'Data', 'Mês', 'Ano', 'Ítem', 'Motivo', 'Tipo',\n",
      "       'Cartão', 'Valor'],\n",
      "      dtype='object')\n",
      "Index(['Local', 'Pessoa', 'Data', 'Mês', 'Ano', 'Ítem', 'Motivo', 'Tipo',\n",
      "       'Cartão', 'Valor'],\n",
      "      dtype='object')\n",
      "Index(['Local', 'Pessoa', 'Data', 'Mês', 'Ano', 'Ítem', 'Motivo', 'Tipo',\n",
      "       'Cartão', 'Valor'],\n",
      "      dtype='object')\n",
      "Index(['Local', 'Pessoa', 'Data', 'Ítem', 'Motivo', 'Tipo', 'Cartão', 'Modo',\n",
      "       'Valor'],\n",
      "      dtype='object')\n",
      "Index(['Local', 'Pessoa', 'Data', 'Ítem', 'Motivo', 'Tipo', 'Cartão', 'Modo',\n",
      "       'Valor'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Printing column name of each sheet to see what need to be change\n",
    "for m in months:\n",
    "    print(dictdf[m].columns)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.Data Selection, addition, deletion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The last 2 months have 'Modo' column, which defines the spending type (credit or debit) and don't have the columns 'Mês' e 'Ano' ('Month' and 'Year', respectively).\n",
    "\n",
    "##### Since my goal is to analyse spending by credit, the first change I made was to drop rows with debit type. And I took the opportunity to add 'Mês' and 'Ano' columns and drop the 'Modo' column, once I don't need it anymore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using enumarate to get the index and the name of the month.\n",
    "for i, m in enumerate(months):\n",
    "    #Since I want just the last two months, I set the index for greater than 9.\n",
    "    if i > 9:        \n",
    "        # Droping the rows and inserting columns.\n",
    "        dictdf[m].drop(dictdf[m][dictdf[m]['Modo'] == 'Débito'].index, inplace = True)\n",
    "        dictdf[m].insert(3, 'Mês', i+1)\n",
    "        dictdf[m].insert(4, 'Ano', 2018)\n",
    "        dictdf[m].drop('Modo', axis =1, inplace = True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Local', 'Pessoa', 'Data', 'Mês', 'Ano', 'Ítem', 'Motivo', 'Tipo',\n",
      "       'Cartão', 'Valor'],\n",
      "      dtype='object')\n",
      "(30, 10)\n",
      "Index(['Local', 'Pessoa', 'Data', 'Mês', 'Ano', 'Ítem', 'Motivo', 'Tipo',\n",
      "       'Cartão', 'Valor'],\n",
      "      dtype='object')\n",
      "(56, 10)\n",
      "Index(['Local', 'Pessoa', 'Data', 'Mês', 'Ano', 'Ítem', 'Motivo', 'Tipo',\n",
      "       'Cartão', 'Valor'],\n",
      "      dtype='object')\n",
      "(35, 10)\n",
      "Index(['Local', 'Pessoa', 'Data', 'Mês', 'Ano', 'Ítem', 'Motivo', 'Tipo',\n",
      "       'Cartão', 'Valor'],\n",
      "      dtype='object')\n",
      "(40, 10)\n",
      "Index(['Local', 'Pessoa', 'Data', 'Mês', 'Ano', 'Ítem', 'Motivo', 'Tipo',\n",
      "       'Cartão', 'Valor'],\n",
      "      dtype='object')\n",
      "(41, 10)\n",
      "Index(['Local', 'Pessoa', 'Data', 'Mês', 'Ano', 'Ítem', 'Motivo', 'Tipo',\n",
      "       'Cartão', 'Valor'],\n",
      "      dtype='object')\n",
      "(55, 10)\n",
      "Index(['Local', 'Pessoa', 'Data', 'Mês', 'Ano', 'Ítem', 'Motivo', 'Tipo',\n",
      "       'Cartão', 'Valor'],\n",
      "      dtype='object')\n",
      "(53, 10)\n",
      "Index(['Local', 'Pessoa', 'Data', 'Mês', 'Ano', 'Ítem', 'Motivo', 'Tipo',\n",
      "       'Cartão', 'Valor'],\n",
      "      dtype='object')\n",
      "(64, 10)\n",
      "Index(['Local', 'Pessoa', 'Data', 'Mês', 'Ano', 'Ítem', 'Motivo', 'Tipo',\n",
      "       'Cartão', 'Valor'],\n",
      "      dtype='object')\n",
      "(54, 10)\n",
      "Index(['Local', 'Pessoa', 'Data', 'Mês', 'Ano', 'Ítem', 'Motivo', 'Tipo',\n",
      "       'Cartão', 'Valor'],\n",
      "      dtype='object')\n",
      "(68, 10)\n",
      "Index(['Local', 'Pessoa', 'Data', 'Mês', 'Ano', 'Ítem', 'Motivo', 'Tipo',\n",
      "       'Cartão', 'Valor'],\n",
      "      dtype='object')\n",
      "(92, 10)\n",
      "Index(['Local', 'Pessoa', 'Data', 'Mês', 'Ano', 'Ítem', 'Motivo', 'Tipo',\n",
      "       'Cartão', 'Valor'],\n",
      "      dtype='object')\n",
      "(69, 10)\n"
     ]
    }
   ],
   "source": [
    "# Verifying column name of each sheet to see if it's the same and its shape.\n",
    "for m in months:\n",
    "    print(dictdf[m].columns)   \n",
    "    print(dictdf[m].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Now all sheet has the same columns names and quantity, but the month number and year aren't right (only on the 2 last months). So I fixed it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, m in enumerate(months):\n",
    "    if i < 10:\n",
    "        for c in range(len(dictdf[m])):\n",
    "            dictdf[m].loc[c, 'Mês'] = (i + 1)\n",
    "            dictdf[m].loc[c, 'Ano'] = 2018\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Now I can concatenate all sheets in just one dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using concat to concatenate all sheets in one dataframe\n",
    "df = pd.concat(dictdf[sheet] for sheet in dictdf.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Droping rows which 'Local' column is a NaN.\n",
    "df.dropna(subset=['Local'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(598, 10)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Droping rows which value is less than 0.\n",
    "df.drop(df[df['Valor'] < 0].index, inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Exporting Excel file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The 2018 dataframe end up with 598 rows and 10 columns. Now I can prepare the data from next years and than concatenate all of them in a single sheet do be able do analyse in visualization software.\n",
    "\n",
    "##### I didn't record the process of 2019 and 2020. So in the next topic I show how I cleand up to remove information that was not needed to create the final file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel('1.2018.Clean.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Unifying the 3 excel files (2018, 2019 e 2020)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Reading all tree files in differents dataframes\n",
    "df2018 = pd.read_excel('1.2018.Clean.xlsx')\n",
    "df2019 = pd.read_excel('2.2019.Clean.xlsx')\n",
    "df2020 = pd.read_excel('3.2020.Clean.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a list with the 3 tables\n",
    "dfs = [df2018[:], df2019[:], df2020[:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ID', 'Local', 'Pessoa', 'Data', 'Mês', 'Ano', 'Ítem', 'Motivo',\n",
      "       'Categoria', 'Tipo', 'Divisão Salarial', 'Cartão', 'Valor'],\n",
      "      dtype='object')\n",
      "Index(['ID', 'Local', 'Pessoa', 'Data', 'Mês', 'Ano', 'Ítem', 'Motivo',\n",
      "       'Categoria', 'Tipo', 'Divisão Salarial', 'Cartão', 'Valor'],\n",
      "      dtype='object')\n",
      "Index(['ID', 'Local', 'Pessoa', 'Data', 'Mês', 'Ano', 'Ítem', 'Motivo',\n",
      "       'Categoria', 'Tipo', 'Divisão Salarial', 'Cartão', 'Valor'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Loop to see the column names\n",
    "for i in dfs:\n",
    "    print(i.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change de name that was created when I exported the files in ID columns\n",
    "for i in range(3):\n",
    "    dfs[i].rename(columns = {'Unnamed: 0':'ID'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inserting columns 'Tipo' and 'Divisão Salarial' in 2018 table\n",
    "dfs[0].insert(9, 'Tipo', '')\n",
    "dfs[0].insert(10, 'Divisão Salarial', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here I tried do reindex the ID, but I couldn't. So I exported the dataframe to do it. \n",
    "fdf = pd.concat(dfs[d][:] for d in range(3))\n",
    "fdf.to_excel('4.FinalDataFrame.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'Unnamed: 0.1', 'ID', 'Local', 'Pessoa', 'Data', 'Mês',\n",
      "       'Ano', 'Ítem', 'Motivo', 'Categoria', 'Tipo', 'Divisão Salarial',\n",
      "       'Cartão', 'Valor'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1352, 15)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Just reading the same dataframe\n",
    "fdf = pd.read_excel('4.FinalDataFrame.xlsx')\n",
    "print(fdf.columns)\n",
    "fdf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ID', 'Local', 'Pessoa', 'Data', 'Mês', 'Ano', 'Ítem', 'Motivo',\n",
      "       'Categoria', 'Tipo', 'Divisão Salarial', 'Cartão', 'Valor'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1352, 13)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dropping the columns that was created by exporting\n",
    "fdf.drop(['Unnamed: 0', 'Unnamed: 0.1'], axis=1, inplace = True)\n",
    "print(fdf.columns)\n",
    "fdf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                  1352\n",
       "Local               1352\n",
       "Pessoa              1352\n",
       "Data                1352\n",
       "Mês                 1352\n",
       "Ano                 1352\n",
       "Ítem                1352\n",
       "Motivo              1352\n",
       "Categoria           1352\n",
       "Tipo                1352\n",
       "Divisão Salarial    1352\n",
       "Cartão              1330\n",
       "Valor               1352\n",
       "dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Counting the number of rows\n",
    "fdf.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping rows with no valid values\n",
    "fdf.drop(fdf[fdf['Pessoa'] != 'Eu'].index, inplace=True)\n",
    "fdf.drop(fdf[fdf['Valor'] <= 0].index, inplace=True)\n",
    "fdf.dropna(subset=['Valor'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                  1352\n",
       "Local               1352\n",
       "Pessoa              1352\n",
       "Data                1352\n",
       "Mês                 1352\n",
       "Ano                 1352\n",
       "Ítem                1352\n",
       "Motivo              1352\n",
       "Categoria           1352\n",
       "Tipo                 929\n",
       "Divisão Salarial     742\n",
       "Cartão              1330\n",
       "Valor               1352\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the numbers\n",
    "fdf.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting the numbers os rows with the same category\n",
    "dupcat = fdf.groupby('Categoria')['Categoria'].count().sort_values(ascending  = False)\n",
    "dupcat = dupcat.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combustível          190\n",
      "Restaurante          151\n",
      "Alimentação          91\n",
      "Lazer                76\n",
      "Presente             73\n",
      "Eletrônico           70\n",
      "Roupas               69\n",
      "Saúde                61\n",
      "Profissional         48\n",
      "Viagem               38\n",
      "Dança                35\n",
      "UBER                 33\n",
      "Celular              33\n",
      "Higiene              30\n",
      "Deslocamento         30\n",
      "Estudo               30\n",
      "Carro                30\n",
      "Estacionamento       26\n",
      "Bicicleta            21\n",
      "Contas               20\n",
      "Transporte           19\n",
      "Lanches              18\n",
      "Streaming            14\n",
      "Capoeira             14\n",
      "Lanche               10\n",
      "Combustítvel         9\n",
      "Cash Back            9\n",
      "Passagem             9\n",
      "Educação             7\n",
      "Combústivel          6\n",
      "Quarto               6\n",
      " Presente            5\n",
      "Necessidade Básica   5\n",
      "Internet             5\n",
      "Intercâmbio          4\n",
      "Cachorro             4\n",
      "Dog                  4\n",
      "TCC                  4\n",
      "Jogo                 4\n",
      "Necessidades Básicas 3\n",
      "Estética             3\n",
      "Jogos                3\n",
      "Pet                  3\n",
      "Tabuleiro            2\n",
      "Roupa                2\n",
      "Casa                 2\n",
      "Pagamentos           2\n",
      "Tarifas              2\n",
      "Arquitetura          1\n",
      "Carri                1\n",
      "Associações          1\n",
      "Tite                 1\n",
      "Vendas               1\n",
      "Bebida               1\n",
      "Besteira             1\n",
      "Comida               1\n",
      "Sushi                1\n",
      "Confeitaria          1\n",
      "Outros               1\n",
      "Decoração            1\n",
      "Necessidades Básica  1\n",
      "Doação               1\n",
      "Juros                1\n",
      "Entregas             1\n",
      "Ergonomia            1\n",
      "Esctacionamento      1\n",
      "Vários               1\n"
     ]
    }
   ],
   "source": [
    "for i, k in dupcat.items():\n",
    "    print(f'{i:<20} {k}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdf.to_excel('4.FinalDataFrame.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Here I decided to use excel to correct the columns 'Categoria', 'Tipo' e 'Divisão Salarial' because it's a personal sheet, so I preferred to look more closely, sometimes at each cell, and change it as I thought necessary. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Uying Excel to correct data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### In the column 'Categoria' I looked up for same categories that had different names or the name was just typed wrong. In addition, I completed the column 'Tipe' based on the date and the item description. The column 'Salary Division' a correct based on the category (column 'Categoria'). I used commands like VLOOKUP and COUNTIFS in this process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Local', 'Pessoa', 'Data', 'Mês', 'Ano', 'Ítem', 'Motivo', 'Categoria',\n",
      "       'Tipo', 'Divisão Salarial', 'Cartão', 'Valor'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1352, 12)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading excel file after changes.\n",
    "fdf = pd.read_excel('4.FinalDataFrameExcel.xlsx')\n",
    "print(fdf.columns)\n",
    "fdf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Local               1352\n",
       "Pessoa              1352\n",
       "Data                1352\n",
       "Mês                 1352\n",
       "Ano                 1352\n",
       "Ítem                1352\n",
       "Motivo              1352\n",
       "Categoria           1352\n",
       "Tipo                1352\n",
       "Divisão Salarial    1352\n",
       "Cartão              1330\n",
       "Valor               1352\n",
       "dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Verifying number os rows in each column.\n",
    "fdf.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### To get the answers I need in my analysis, I’m only going to use the columns 'Data', 'Mês', 'Ano', 'Categoria', 'Tipo', 'Divisão Salarial', 'Valor'. So I can drop the rest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Data', 'Mês', 'Ano', 'Categoria', 'Tipo', 'Divisão Salarial', 'Valor'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1352, 7)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Droppin columns that I don't need anymore.\n",
    "\n",
    "fdf.drop('Local', axis=1, inplace = True)\n",
    "fdf.drop('Pessoa', axis=1, inplace = True)\n",
    "fdf.drop('Cartão', axis=1, inplace = True)\n",
    "fdf.drop('Ítem', axis=1, inplace = True)\n",
    "fdf.drop('Motivo', axis=1, inplace = True)\n",
    "print(fdf.columns)\n",
    "fdf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Now my table is clean and prepared. I'm able to do my analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdf.to_excel('4.FinalTable.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
